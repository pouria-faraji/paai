version: '2'

services:
  spark-master:
    image: bitnami/spark:3.3
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
      - '7077:7077'
    expose:
      - 7077
    networks:
      - mongo_default
      - default

    # command: spark-submit /pyspark_job.py
  spark-worker:
    image: bitnami/spark:3.3
    networks:
      - mongo_default
      - default
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

  spark-job:
    image: bitnami/spark:3.3
    networks:
      - mongo_default
      - default
    volumes:
      - ./pyspark_job.py:/pyspark_job.py
    command: spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.2,org.mongodb.spark:mongo-spark-connector_2.12:10.1.1 --master spark://spark-master:7077 /pyspark_job.py 

networks:
  default:
  mongo_default:
    external: true